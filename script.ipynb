{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spring's constant measuring\n",
    "\n",
    "TODO:\n",
    "analyze dinamic dataset\n",
    "create the plots\n",
    "get the coefficients with linear regression\n",
    "use chi2 to see if its correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.signal as spy\n",
    "import math\n",
    "\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "\n",
    "csv_data = []\n",
    "excel_data = []\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        current_file_path = os.path.join(root, file).replace(\n",
    "            \"\\\\\", \"/\"\n",
    "        )  # fix the unbearably frustrating flaws of the wanna-be OS... \"Windows\"\n",
    "        if \"xlsx\" in file:\n",
    "            excel_data.append(current_file_path)\n",
    "        elif \"csv\" in file:\n",
    "            csv_data.append(current_file_path)\n",
    "    break\n",
    "\n",
    "del root, dirs, files, current_file_path, data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions to read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename: str):\n",
    "    data = pd.read_csv(filename, sep=\";\").replace(\",\", \".\", regex=True)\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    data.drop(\n",
    "        index=data.index[0], axis=0, inplace=True\n",
    "    )  # instrument error causes first value to be nonsensical\n",
    "\n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].apply(pd.to_numeric)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_excel(filename: str):\n",
    "    data = pd.read_excel(filename)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets to a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict()\n",
    "\n",
    "for file in csv_data + excel_data:\n",
    "    key = os.path.basename(file).split(\".\")[0]\n",
    "    if \"csv\" in file:\n",
    "        datasets[key] = read_csv(file)\n",
    "    elif \"xlsx\" in file:\n",
    "        datasets[key] = read_excel(file)\n",
    "\n",
    "for k in datasets.keys():\n",
    "    print(f\"\\nkey: {k}\")\n",
    "    datasets[k].info()\n",
    "\n",
    "del k, key, file, csv_data, excel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling frequencies in Hz\n",
    "\n",
    "static_sampling_frequency = 100\n",
    "dynamic_sampling_frequency = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_keys = list(filter(lambda k: \"statico\" in k, datasets.keys()))\n",
    "dynamic_keys = list(filter(lambda k: \"dinamico\" in k, datasets.keys()))\n",
    "\n",
    "\n",
    "static_datasets = {k: datasets[k] for k in static_keys}\n",
    "dynamic_datasets = {k: datasets[k] for k in dynamic_keys}\n",
    "\n",
    "del static_keys, dynamic_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_masses = dict()\n",
    "ds = datasets[\"misure_masse\"]\n",
    "objects = [str(e) for e in ds.iloc[:, 0].array.tolist()]\n",
    "masses = ds.iloc[:, 1].array.tolist()\n",
    "\n",
    "for i in range(len(objects)):\n",
    "    object_masses[objects[i]] = masses[i]\n",
    "print(object_masses)\n",
    "\n",
    "del ds, objects, masses, i, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_mass(\n",
    "    used_masses: str, spring_used: str, has_support_structure: bool = True\n",
    "):\n",
    "    used_masses = str(used_masses)\n",
    "    total_mass = object_masses[spring_used]\n",
    "    if has_support_structure:\n",
    "        total_mass += object_masses[\"piatto\"] + object_masses[\"supporto\"]\n",
    "\n",
    "    for m in [s for s in used_masses.split(\",\") if s]:\n",
    "        if m in object_masses.keys():\n",
    "            total_mass += object_masses[m]\n",
    "\n",
    "    return total_mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for linear regression and chi2\n",
    "\n",
    "$$ y = Ax + B$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinRef(*, x: List[float], y: List[float]) -> Dict[str, float]:\n",
    "    pass\n",
    "\n",
    "\n",
    "def chi2(\n",
    "    *, Ei: List[float], Oi: List[float], sigmai: List[float], deg_freedom: int\n",
    ") -> Dict[str, float]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze static\n",
    "\n",
    "```results``` nella forma di: [[massa * 9.805 (quindi il peso), lunghezza], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_calibre_data(dataset_name: str):\n",
    "    used_spring = \"molla \" + dataset_name[8:-8:].replace(\"-\", \" \")\n",
    "\n",
    "    used_masses = static_datasets[dataset_name].iloc[:, 0].array.tolist()\n",
    "    mm_lengths = static_datasets[dataset_name].iloc[:, 1].array.tolist()\n",
    "    # in_lengths = static_datasets[dataset_name].iloc[:, 2].array.tolist()\n",
    "\n",
    "    print(f\"\\nDataset: {dataset_name}\\nSpring: {used_spring}\\nMasses: {used_masses}\")\n",
    "\n",
    "    results = np.ndarray((len(used_masses), 2))\n",
    "\n",
    "    for idx, used_masses in enumerate(used_masses):\n",
    "        results[idx] = [\n",
    "            9.805 * calculate_total_mass(used_masses, used_spring),\n",
    "            mm_lengths[idx],\n",
    "        ]\n",
    "\n",
    "    print(\"Results in array form (weight-length):\", results, end=\"\\n------------\\n\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_sonar_data(dataset_name: str):\n",
    "    used_spring = \"molla \" + dataset_name[6:-8:].replace(\"-\", \" \")\n",
    "\n",
    "    used_masses = static_datasets[\"masse_\" + dataset_name].iloc[:, 0].array.tolist()\n",
    "    runs = static_datasets[dataset_name]\n",
    "\n",
    "    print(f\"\\nDataset: {dataset_name}\\nSpring: {used_spring}\\nMasses: {used_masses}\")\n",
    "\n",
    "    results = np.ndarray((len(used_masses), 2))\n",
    "\n",
    "    for idx, run_name in enumerate(runs.columns):\n",
    "        # print(runs[run_name].array)\n",
    "        signal = runs[run_name]\n",
    "        results[idx] = [\n",
    "            9.805 * calculate_total_mass(used_masses[idx], used_spring),\n",
    "            np.mean(signal),\n",
    "        ]\n",
    "\n",
    "    print(\"Results in array form (weight-length):\\n\", results, end=\"\\n------------\\n\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_static_dataset(dataset_name: str):\n",
    "    if \"calibro\" in dataset_name:\n",
    "        return analyze_calibre_data(dataset_name)\n",
    "    elif \"sonar\" in dataset_name:\n",
    "        return analyze_sonar_data(dataset_name)\n",
    "\n",
    "\n",
    "final_static_data = dict()\n",
    "\n",
    "for key in filter(lambda e: not \"masse\" in e, static_datasets.keys()):\n",
    "    final_static_data[key] = analyze_static_dataset(key)\n",
    "\n",
    "del key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze dinamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_period(signal: list):\n",
    "    peaks, _ = spy.find_peaks(signal, width=10)\n",
    "    mean = np.mean(signal)\n",
    "    peaks = list(filter(lambda e: e >= mean, peaks))\n",
    "\n",
    "    acc_mean = 0\n",
    "    for i in range(len(peaks) - 1):\n",
    "        acc_mean += abs(peaks[i] - peaks[i + 1]) / dynamic_sampling_frequency\n",
    "    mean = acc_mean / (len(peaks) - 1)\n",
    "\n",
    "    acc_sigma = 0\n",
    "    for i in range(len(peaks) - 1):\n",
    "        acc_sigma += (\n",
    "            abs((peaks[i] - peaks[i + 1]) / dynamic_sampling_frequency) - mean\n",
    "        ) ** 2\n",
    "    sigma = math.sqrt(acc_sigma / (len(peaks) - 1))\n",
    "\n",
    "    return (mean, sigma / math.sqrt(len(peaks) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of the oscillations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plt.figure(figsize=(16, 9))\n",
    "# test run:\n",
    "for j in range(len(dynamic_datasets[\"sonar_non-pretensionata_dinamico\"])):\n",
    "    _signal = (\n",
    "        dynamic_datasets[\"sonar_non-pretensionata_dinamico\"].iloc[:, j].array.tolist()\n",
    "    )\n",
    "    _peaks, _ = spy.find_peaks(_signal, width=10)\n",
    "    _mean = np.mean(_signal)\n",
    "    _peaks = list(filter(lambda e: e >= _mean, _peaks))\n",
    "\n",
    "    print(len(_peaks))\n",
    "\n",
    "    plt.title(\"Molla non pretensionata dinamico\")\n",
    "    plt.xlabel(\"Tempo [s]\")\n",
    "    plt.ylabel(\"Spostamento [mm]\")\n",
    "    plt.plot(\n",
    "        [i / dynamic_sampling_frequency for i in range(len(_signal))], _signal, lw=1.2\n",
    "    )\n",
    "    plt.scatter(\n",
    "        [x / dynamic_sampling_frequency for x in _peaks],\n",
    "        [_signal[x] for x in _peaks],\n",
    "        marker=\"x\",\n",
    "        s=21,\n",
    "    )\n",
    "\n",
    "    _acc = 0\n",
    "    for i in range(len(_peaks) - 1):\n",
    "        _acc += abs(_peaks[i] - _peaks[i + 1]) / dynamic_sampling_frequency\n",
    "    _mean = _acc / (len(_peaks) - 1)\n",
    "\n",
    "    print(_mean, _mean / math.sqrt(len(_peaks) - 1))\n",
    "\n",
    "del _signal\n",
    "del _peaks\n",
    "del _mean\n",
    "del _acc\n",
    "del _\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make graphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
